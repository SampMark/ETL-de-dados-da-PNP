{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cd631fb",
        "outputId": "f0af5382-801f-40eb-e94b-cebee616a7de"
      },
      "source": [
        "# Instalar dependências\n",
        "!pip install unidecode google-api-python-client gspread rapidfuzz beautifulsoup4 lxml --upgrade --quiet\n",
        "!pip install requests==2.32.4 --quiet\n",
        "\n",
        "print(\"Dependências instaladas com sucesso!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDependências instaladas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# Importar bibliotecas\n",
        "from __future__ import annotations\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "from dataclasses import dataclass, asdict\n",
        "from bs4 import BeautifulSoup\n",
        "from rapidfuzz import fuzz, process as rf_process\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random, time, requests, re, os\n",
        "import unicodedata\n",
        "from unidecode import unidecode\n",
        "\n",
        "# Autenticação e cliente gspread\n",
        "import google.auth\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from gspread.client import Client\n",
        "\n",
        "print(\"Bibliotecas instaladas com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lCZoNiz3FLa",
        "outputId": "0de029c4-481b-42f7-be5c-00d438b61510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas instaladas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **ETAPA 2.1. Geração do `df_mapa_RFEPT` obtido via Web Scraping**\n",
        "# para mesclagem visando a complementação de informações de `df_rede_federal` (ETAPA 1)\n",
        "\n",
        "# --- CONSTANTES GLOBAIS ---\n",
        "\n",
        "# URL base do portal do MEC para a Rede Federal\n",
        "URL_BASE = \"https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/{uf}\"\n",
        "\n",
        "# Lista das 27 Unidades Federativas do Brasil\n",
        "UFS = [\n",
        "    \"acre\",\"alagoas\",\"amapa\",\"amazonas\",\"bahia\",\"ceara\",\"distrito-federal\",\"espirito-santo\",\n",
        "    \"goias\",\"maranhao\",\"mato-grosso\",\"mato-grosso-do-sul\",\"minas-gerais\",\"para\",\"paraiba\",\n",
        "    \"parana\",\"pernambuco\",\"piaui\",\"rio-de-janeiro\",\"rio-grande-do-norte\",\"rio-grande-do-sul\",\n",
        "    \"rondonia\",\"roraima\",\"santa-catarina\",\"sao-paulo\",\"sergipe\",\"tocantins\",\n",
        "]\n",
        "\n",
        "# Cabeçalho da requisição para simular um navegador e evitar bloqueios\n",
        "HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "# SESSION = requests.Session()\n",
        "# SESSION.headers.update(HEADERS)\n",
        "\n",
        "# Textos que indicam um campo vazio ou não preenchido\n",
        "PLACEHOLDER_TEXTS = [\n",
        "    'não especificado', 'não informado', 'informação indisponível',\n",
        "    'não há', 'não se aplica'\n",
        "]\n",
        "\n",
        "# Palavras-chave para identificar o início de um bloco de instituição (Reitoria)\n",
        "INSTITUTION_KEYWORDS = ['INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNOLOGIA',\n",
        "                        'CEFET',\n",
        "                        'UNIVERSIDADE TECNOLÓGICA FEDERAL'\n",
        "                        ]"
      ],
      "metadata": {
        "id": "qAa3QjlSO7a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Função `scrape_all_ufs`**\n",
        "\n",
        "Esta função orquestra todo o processo de _web scraping_, itera sobre a lista de UFs, gerencia as requisições HTTP e delega a análise do conteúdo para funções auxiliares."
      ],
      "metadata": {
        "id": "nPWnORtcPMBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_all_ufs():\n",
        "    \"\"\"\n",
        "    Orquestra o processo de scraping para todas as 27 Unidades Federativas.\n",
        "\n",
        "    Itera sobre a lista de UFS, faz as requisições HTTP, trata possíveis erros\n",
        "    de conexão e agrega os resultados de cada página em uma lista única.\n",
        "\n",
        "    Returns:\n",
        "        list: Uma lista de dicionários, onde cada dicionário contém os dados\n",
        "              de uma unidade (Reitoria ou Campus).\n",
        "    \"\"\"\n",
        "    all_data = []\n",
        "    log_summary = []\n",
        "\n",
        "    print(\"Iniciando processo de extração de dados da Rede Federal...\")\n",
        "\n",
        "    for uf in UFS:\n",
        "        url = URL_BASE.format(uf=uf.lower())\n",
        "        print(f\"Processando UF: {uf.upper()} | URL: {url}\")\n",
        "\n",
        "        try:\n",
        "            # Realiza a requisição HTTP com um timeout de 20 segundos\n",
        "            response = requests.get(url, headers=HEADERS, timeout=20)\n",
        "            # Levanta uma exceção para códigos de status de erro (4xx ou 5xx)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Passa o conteúdo HTML para a função de parsing\n",
        "            # uf_data = parse_uf_page(response.content, uf.upper())\n",
        "            uf_data = parse_uf_page(response.content, uf)\n",
        "\n",
        "            if uf_data:\n",
        "                all_data.extend(uf_data)\n",
        "                log_summary.append({\n",
        "                    'UF': uf.upper(),\n",
        "                    'Status': 'Success',\n",
        "                    'Units Found': len(uf_data)})\n",
        "                print(f\"  -> Sucesso: {len(uf_data)} unidades encontradas.\")\n",
        "            else:\n",
        "                log_summary.append({\n",
        "                    'UF': uf.upper(),\n",
        "                    'Status': 'Failed - No Data Found',\n",
        "                    'Institutes Found': 0,\n",
        "                    'Campuses Found': 0\n",
        "                })\n",
        "                print(\"  -> Alerta: Página acessada, mas nenhum dado estruturado foi encontrado.\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "        # Captura erros de rede, timeout, ou status HTTP de erro\n",
        "            log_summary.append({\n",
        "                'UF': uf.upper(),\n",
        "                'Status': f'Failed - {type(e).__name__}',\n",
        "                'Units Found': 0})\n",
        "            print(f\"  -> ERRO: Falha ao acessar a URL. Motivo: {e}\")\n",
        "\n",
        "        # Pausa de 3 segundos entre as requisições para não sobrecarregar o servidor\n",
        "        time.sleep(3)\n",
        "\n",
        "    print(\"\\nProcesso de extração finalizado.\")\n",
        "    return all_data, log_summary"
      ],
      "metadata": {
        "id": "C0knWmNBPFAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Função `parse_uf_page` (análise e extração)**\n",
        "Esta função é o core do script, recebe o conteúdo HTML de uma página, aplica a lógica de _parsing_ com estado para identificar Reitorias e Campi, e utiliza funções auxiliares para extrair os dados de forma defensiva."
      ],
      "metadata": {
        "id": "LZXWWmrYPmJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extrair_informacoes(url):\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "        # Dicionário para armazenar os dados\n",
        "        dados = {'Endereço': None, 'CEP': None, 'Telefone': None, 'E-mail': None, 'Site': None}\n",
        "\n",
        "        # --- Correção 1: Seletores de Container Flexíveis ---\n",
        "        seletores_container = [\n",
        "            'div.content-col-content',     # Padrão antigo\n",
        "            'article#parent-fieldname-text', # Padrão Plone\n",
        "            'div#content-core',            # Padrão Plone\n",
        "            'div#portal-column-content',   # Padrão Plone\n",
        "            'div.entry-content',           # Padrão Wordpress\n",
        "            'div#content',\n",
        "            'main#main-content',\n",
        "            'main',\n",
        "            'article',\n",
        "            'body' # Em último caso, usa o corpo todo\n",
        "        ]\n",
        "\n",
        "        container = None\n",
        "        for seletor in seletores_container:\n",
        "            container = soup.select_one(seletor)\n",
        "            if container:\n",
        "                # print(f\"DEBUG: Container encontrado com o seletor: {seletor} em {url}\")\n",
        "                break\n",
        "\n",
        "        if not container:\n",
        "            print(f\"ALERTA: Nenhum container encontrado para a URL: {url}\")\n",
        "            return dados # Retorna dados vazios\n",
        "\n",
        "        # --- Correção 2: Extração baseada em Pistas ---\n",
        "\n",
        "        # 1. Extrair Telefone\n",
        "        pistas_tel = ['fa-phone', 'icon-phone', 'Telefone:', 'Tel.:', 'Fone:']\n",
        "        dados['Telefone'] = buscar_info_por_pista(container, pistas_tel, 'telefone', url)\n",
        "\n",
        "        # 2. Extrair E-mail\n",
        "        pistas_email = ['fa-envelope', 'icon-envelope', 'E-mail:', 'Email:', 'Correio Eletrônico:']\n",
        "        dados['E-mail'] = buscar_info_por_pista(container, pistas_email, 'email', url)\n",
        "\n",
        "        # 3. Extrair Endereço\n",
        "        pistas_end = ['fa-map-marker', 'icon-map-marker', 'Endereço:', 'Localização:']\n",
        "        dados['Endereço'] = buscar_info_por_pista(container, pistas_end, 'endereco', url)\n",
        "\n",
        "        # 4. Extrair CEP (Muitas vezes vem junto com o endereço ou tem sua própria pista)\n",
        "        pistas_cep = ['CEP:']\n",
        "        dados['CEP'] = buscar_info_por_pista(container, pistas_cep, 'cep', url)\n",
        "\n",
        "        # 5. Extrair Site (Lógica um pouco diferente)\n",
        "        pistas_site = ['fa-globe', 'icon-globe', 'Site:', 'Página:', 'Portal:']\n",
        "        try:\n",
        "            el_site = None\n",
        "            for pista in pistas_site:\n",
        "                elemento_encontrado = None\n",
        "                if pista.startswith('fa-') or pista.startswith('icon-'):\n",
        "                    elemento_encontrado = container.select_one(f\"[class*='{pista}']\")\n",
        "                else:\n",
        "                    elemento_encontrado = container.find(string=re.compile(pista, re.IGNORECASE))\n",
        "\n",
        "                if elemento_encontrado:\n",
        "                    # Procura o link '<a>' no elemento \"pai\"\n",
        "                    el_pai = elemento_encontrado.parent\n",
        "                    link_site = el_pai.find('a', href=re.compile(r'http'))\n",
        "                    if link_site and 'mailto:' not in link_site['href']:\n",
        "                        dados['Site'] = link_site['href'].strip()\n",
        "                        break\n",
        "\n",
        "            # Fallback (Plano B) para Site: Procurar o primeiro link 'http'\n",
        "            # que pareça ser o site principal (evitar links de redes sociais)\n",
        "            if not dados['Site']:\n",
        "                todos_links = container.find_all('a', href=re.compile(r'http'))\n",
        "                for link in todos_links:\n",
        "                     href = link['href']\n",
        "                     if 'mailto:' not in href and 'facebook.com' not in href and \\\n",
        "                        'instagram.com' not in href and 'youtube.com' not in href and \\\n",
        "                        url not in href: # Evita links para a própria página\n",
        "\n",
        "                         dados['Site'] = href.strip()\n",
        "                         break # Pega o primeiro link externo válido\n",
        "        except Exception:\n",
        "            pass # Falha silenciosa na busca do site\n",
        "\n",
        "\n",
        "        # --- PLANO B (Fallback) ---\n",
        "        # Se a busca por pistas falhou, tentamos o método antigo (Regex no texto todo)\n",
        "        # Isso garante que não perdemos dados que o script antigo já pegava\n",
        "\n",
        "        full_text = container.get_text(strip=True, separator=' ')\n",
        "\n",
        "        if not dados['Telefone']:\n",
        "            match = re.search(r'((?:\\(?\\b\\d{2}\\)?\\s?)?\\d{4,5}[-.\\s]?\\d{4})', full_text)\n",
        "            if match: dados['Telefone'] = match.group(1).strip()\n",
        "\n",
        "        if not dados['E-mail']:\n",
        "            match = re.search(r'([\\w\\.-]+@[\\w\\.-]+\\.\\w+)', full_text, re.IGNORECASE)\n",
        "            if match: dados['E-mail'] = match.group(1).strip()\n",
        "\n",
        "        # O CEP pode estar no endereço, então buscamos ele antes de limpar\n",
        "        if not dados['CEP']:\n",
        "            match_cep_fallback = re.search(r'(\\b\\d{5}-?\\d{3}\\b)', full_text)\n",
        "            if match_cep_fallback:\n",
        "                dados['CEP'] = match_cep_fallback.group(1).strip()\n",
        "                # Se o endereço foi pego junto, vamos usá-lo\n",
        "                if not dados['Endereço']:\n",
        "                     # Tenta pegar o texto ao redor do CEP (Contexto)\n",
        "                    texto_proximo = full_text[max(0, match_cep_fallback.start()-100) : match_cep_fallback.end()+50]\n",
        "                    # Tenta limpar o contexto\n",
        "                    if 'Endereço:' in texto_proximo:\n",
        "                         texto_proximo = texto_proximo.split('Endereço:')[1]\n",
        "                    dados['Endereço'] = texto_proximo.strip(' ,-')\n",
        "\n",
        "\n",
        "        # --- Limpeza Final ---\n",
        "        # Se o CEP foi pego (pela pista ou fallback) e também está dentro do Endereço\n",
        "        if dados['Endereço'] and dados['CEP'] and dados['CEP'] in dados['Endereço']:\n",
        "            # Remove o CEP e o texto \"CEP:\" do endereço\n",
        "            dados['Endereço'] = dados['Endereço'].replace(dados['CEP'], '').strip()\n",
        "            dados['Endereço'] = re.sub(r'CEP:?', '', dados['Endereço'], flags=re.IGNORECASE).strip(' ,-')\n",
        "\n",
        "        return dados\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Erro ao acessar {url}: {e}\")\n",
        "        return {'Endereço': None, 'CEP': None, 'Telefone': None, 'E-mail': None, 'Site': None}"
      ],
      "metadata": {
        "id": "FEP8DXiG_1NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_uf_page(html_content, uf_sigla):\n",
        "    \"\"\"\n",
        "    Analisa o conteúdo HTML de uma página de UF e extrai os dados das instituições.\n",
        "    Primeiro, localiza os títulos e depois processa o bloco pai correspondente.\n",
        "\n",
        "    Implementa uma lógica 'stateful' para associar corretamente os campi às suas\n",
        "    respectivas reitorias, especialmente em páginas com múltiplos institutos.\n",
        "\n",
        "    Args:\n",
        "        html_content (bytes): O conteúdo HTML bruto da página.\n",
        "        uf_sigla (str): A sigla da UF sendo processada (ex: 'SP').\n",
        "\n",
        "    Returns:\n",
        "        list: Uma lista de dicionários com os dados das unidades encontradas na página.\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    content_area = soup.find(id='content-core')\n",
        "    if not content_area:\n",
        "        return\n",
        "\n",
        "    all_units_data = []\n",
        "    current_institute_info = {}\n",
        "\n",
        "    # Abordagem mais robusta: encontrar todos os títulos e iterar sobre eles\n",
        "    titles = content_area.find_all(['b', 'strong'])\n",
        "\n",
        "    for title in titles:\n",
        "        text = title.get_text(strip=True).upper()\n",
        "\n",
        "        # Encontra o contêiner do bloco (ex: <p>, <td>, <div>)\n",
        "        parent_block = title.find_parent(['p', 'td', 'div'])\n",
        "        if not parent_block:\n",
        "            continue\n",
        "\n",
        "        # Verifica se é um bloco de Instituição\n",
        "        if any(keyword in text for keyword in INSTITUTION_KEYWORDS):\n",
        "            institution_data = parse_institution_block(parent_block, uf_sigla)\n",
        "            if institution_data:\n",
        "                current_institute_info = {\n",
        "                    'Nome_IF': institution_data.get('Nome_IF'),\n",
        "                    'Sigla_IF': institution_data.get('Sigla_IF'),\n",
        "                    'Site': institution_data.get('Site')\n",
        "                }\n",
        "                all_units_data.append(institution_data)\n",
        "\n",
        "        # Verifica se é um bloco de Campus\n",
        "        elif text.startswith(\"CAMPUS\"):\n",
        "            if not current_institute_info:\n",
        "                continue  # Evita campus órfão\n",
        "\n",
        "            campus_data = parse_campus_block(parent_block, uf_sigla)\n",
        "            if campus_data:\n",
        "                # Combina os dados do instituto com os dados do campus\n",
        "                full_data = {**current_institute_info, **campus_data}\n",
        "                all_units_data.append(full_data)\n",
        "\n",
        "    return all_units_data"
      ],
      "metadata": {
        "id": "0RmSk01rPjRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buscar_info_por_pista(container, pistas, tipo_info, debug_url=''):\n",
        "    \"\"\"\n",
        "    Procura por elementos que contenham 'pistas' (texto ou classes CSS)\n",
        "    e extrai a informação relevante (próximo texto ou atributo).\n",
        "\n",
        "    pistas: lista de strings para procurar (ex: ['fa-phone', 'Telefone:'])\n",
        "    tipo_info: 'email', 'telefone', 'cep', 'site', 'endereco'\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # 1. Tenta procurar por texto visível (ex: \"Telefone:\")\n",
        "        # Usamos 're.compile' para ignorar maiúsculas/minúsculas (case-insensitive)\n",
        "        elementos_pista = container.find_all(string=re.compile(r'|'.join(pistas), re.IGNORECASE))\n",
        "\n",
        "        if elementos_pista:\n",
        "            for el in elementos_pista:\n",
        "                # A informação pode estar no texto do elemento \"pai\"\n",
        "                texto_pai = el.parent.get_text(strip=True, separator=' ')\n",
        "\n",
        "                # Tenta extrair usando regex específico do tipo\n",
        "                if tipo_info == 'telefone':\n",
        "                    match = re.search(r'((?:\\(?\\b\\d{2}\\)?\\s?)?\\d{4,5}[-.\\s]?\\d{4})', texto_pai)\n",
        "                    if match: return match.group(1).strip()\n",
        "\n",
        "                if tipo_info == 'email':\n",
        "                    # O email pode estar num link 'mailto:' próximo\n",
        "                    link_email = el.parent.find('a', href=re.compile(r'mailto:'))\n",
        "                    if link_email:\n",
        "                        return link_email['href'].replace('mailto:', '').strip()\n",
        "                    match = re.search(r'([\\w\\.-]+@[\\w\\.-]+\\.\\w+)', texto_pai, re.IGNORECASE)\n",
        "                    if match: return match.group(1).strip()\n",
        "\n",
        "                if tipo_info == 'cep':\n",
        "                    match = re.search(r'(\\b\\d{5}-?\\d{3}\\b)', texto_pai)\n",
        "                    if match: return match.group(1).strip()\n",
        "\n",
        "                if tipo_info == 'endereco':\n",
        "                    # Remove a pista (ex: \"Endereço:\") do texto\n",
        "                    texto_limpo = re.sub(r'|'.join(pistas), '', texto_pai, flags=re.IGNORECASE).strip(' :')\n",
        "                    # Verifica se sobrou texto útil (evita pegar só um \"Endereço:\")\n",
        "                    if len(texto_limpo) > 10:\n",
        "                        return texto_limpo\n",
        "\n",
        "        # 2. Se não achou por texto, tenta por classes CSS (ícones)\n",
        "        classes_css = [p for p in pistas if p.startswith('fa-') or p.startswith('icon-')]\n",
        "        if classes_css:\n",
        "            # Constrói um seletor CSS (ex: \"[class*='fa-phone'], [class*='icon-phone']\")\n",
        "            seletor_icone = ', '.join([f\"[class*='{c}']\" for c in classes_css])\n",
        "            el_icone = container.select_one(seletor_icone)\n",
        "\n",
        "            if el_icone:\n",
        "                # A informação geralmente está no texto do elemento \"pai\"\n",
        "                elemento_pai = el_icone.parent\n",
        "                # Às vezes, o elemento pai é o próprio link (ex: <a><i class=\"fa-phone\"></i> (44)...</a>)\n",
        "                # Vamos subir até 2 níveis se necessário\n",
        "                if len(elemento_pai.get_text(strip=True)) < 8 and elemento_pai.parent:\n",
        "                    elemento_pai = elemento_pai.parent\n",
        "\n",
        "                texto_pai_icone = elemento_pai.get_text(strip=True, separator=' ')\n",
        "\n",
        "                if tipo_info == 'telefone':\n",
        "                    match = re.search(r'((?:\\(?\\b\\d{2}\\)?\\s?)?\\d{4,5}[-.\\s]?\\d{4})', texto_pai_icone)\n",
        "                    if match: return match.group(1).strip()\n",
        "\n",
        "                if tipo_info == 'email':\n",
        "                    link_email = elemento_pai.find('a', href=re.compile(r'mailto:'))\n",
        "                    if link_email:\n",
        "                        return link_email['href'].replace('mailto:', '').strip()\n",
        "                    match = re.search(r'([\\w\\.-]+@[\\w\\.-]+\\.\\w+)', texto_pai_icone, re.IGNORECASE)\n",
        "                    if match: return match.group(1).strip()\n",
        "\n",
        "                if tipo_info == 'cep':\n",
        "                    match = re.search(r'(\\b\\d{5}-?\\d{3}\\b)', texto_pai_icone)\n",
        "                    if match: return match.group(1).strip()\n",
        "\n",
        "                if tipo_info == 'endereco':\n",
        "                     # Remove a pista (ex: \"Endereço:\") do texto\n",
        "                    texto_limpo = re.sub(r'|'.join(pistas), '', texto_pai_icone, flags=re.IGNORECASE).strip(' :')\n",
        "                    if len(texto_limpo) > 10:\n",
        "                        return texto_limpo\n",
        "\n",
        "    except Exception as e:\n",
        "        # print(f\"Erro ao buscar '{tipo_info}' em {debug_url}: {e}\")\n",
        "        pass # Continua silenciosamente\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "o2axuRTn_KqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_field(block, label):\n",
        "    \"\"\"\n",
        "    Função de extração defensiva genérica. Busca um rótulo e extrai o texto subsequente.\n",
        "\n",
        "    Args:\n",
        "        block (bs4.element.Tag): O objeto BeautifulSoup do bloco de conteúdo.\n",
        "        label (str): O rótulo de texto a ser procurado (ex: 'Telefone:').\n",
        "\n",
        "    Returns:\n",
        "        str or None: O valor limpo do campo, ou None se não for encontrado ou for um placeholder.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        block_text = block.get_text('\\n', strip=True)  # Define block_text here\n",
        "        # Usa regex para encontrar o rótulo de forma flexível (ignorando maiúsculas/minúsculas)\n",
        "        # e captura o texto até o próximo rótulo ou final da linha.\n",
        "        # Usa raw string (r\"...\") para evitar SyntaxWarning com '\\s'\n",
        "\n",
        "        # pattern = re.compile(rf\"{re.escape(label)}[:\\s]*([^\\n\\r]+)\", re.IGNORECASE)\n",
        "        pattern = re.compile(f\"{re.escape(label)}[:\\\\s]*([^\\\\n\\\\r]+)\", re.IGNORECASE)\n",
        "        # match = pattern.search(block.get_text('\\n', strip=True))\n",
        "        match = pattern.search(block_text)\n",
        "        if match:\n",
        "            value = match.group(1).strip()\n",
        "            # Verifica se o valor extraído não é um placeholder\n",
        "            if not any(ph.lower() in value.lower() for ph in PLACEHOLDER_TEXTS):\n",
        "                return value\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_email(block):\n",
        "    \"\"\"Função aprimorada para extrair e-mail, procurando por links 'mailto:'.\"\"\"\n",
        "    try:\n",
        "        # Prioriza a busca por links mailto:, que é a forma mais comum e confiável\n",
        "        email_link = block.find('a', href=re.compile(r'^mailto:'))\n",
        "        if email_link:\n",
        "            return email_link.get_text(strip=True)\n",
        "\n",
        "        # Se não encontrar, tenta a extração baseada em texto como fallback\n",
        "        return extract_field(block, 'E-mail')\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def parse_location_string(block_text, uf_name):\n",
        "    \"\"\"Analisa o texto para extrair Município, UF e CEP com base em padrões comuns.\"\"\"\n",
        "    # Converte o nome completo da UF (ex: \"sao-paulo\") para a sigla (ex: \"SP\") para fallback\n",
        "    uf_sigla = ''.join([word for word in uf_name.split('-')]).upper()\n",
        "    if len(uf_sigla) > 2: # Heurística simples para siglas compostas\n",
        "        uf_sigla = ''.join([word for word in uf_name.upper().split('-')])\n",
        "\n",
        "    municipio, uf, cep = None, uf_sigla, None\n",
        "\n",
        "    # Padrão 1: \"Cidade/UF - CEP: 12345-678\"\n",
        "    match = re.search(r'([A-Za-z\\s\\'-À-ú]+)\\s*/\\s*([A-Z]{2})\\s*-\\s*CEP:\\s*(\\d{5}-\\d{3})', block_text)\n",
        "    if match:\n",
        "        municipio = match.group(1).strip().rstrip('., ')\n",
        "        uf = match.group(2).strip()\n",
        "        cep = match.group(3).strip()\n",
        "    else:\n",
        "        # Padrão 2 (fallback): Tenta extrair apenas o CEP se o padrão completo falhar\n",
        "        cep_match = re.search(r'(\\d{5}-\\d{3})', block_text)\n",
        "        if cep_match:\n",
        "            cep = cep_match.group(1)\n",
        "\n",
        "    return {'Município': municipio, 'UF': uf, 'CEP': cep}\n",
        "\n",
        "# -----------------------------------\n",
        "# --- FUNÇÕES DE PARSING DE BLOCO ---\n",
        "# -----------------------------------\n",
        "\n",
        "def parse_institution_block(block, uf_name):\n",
        "    \"\"\"Extrai e estrutura os dados de um bloco de Instituição (Reitoria).\"\"\"\n",
        "    block_text = block.get_text('\\n', strip=True)\n",
        "\n",
        "    # Extrai o nome completo da instituição\n",
        "    title_tag = block.find(['b', 'strong'])\n",
        "    nome_if = title_tag.get_text(strip=True) if title_tag else \"\"\n",
        "\n",
        "    # Extrai a sigla do nome completo (ex: (IFSP))\n",
        "    sigla_match = re.search(r'\\((.*?)\\)', nome_if)\n",
        "    sigla_if = sigla_match.group(1) if sigla_match else None\n",
        "\n",
        "    # Limpa o nome do IF removendo a sigla\n",
        "    nome_if_clean = re.sub(r'\\s*\\((.*?)\\)', '', nome_if).strip()\n",
        "\n",
        "    location_parts = parse_location_string(block_text, uf_name)\n",
        "\n",
        "    return {\n",
        "        'Sigla_IF': sigla_if,\n",
        "        'Nome_IF': nome_if_clean,\n",
        "        'Campus_IF': 'Reitoria',\n",
        "        'Município': location_parts['Município'],\n",
        "        'UF': location_parts['UF'],\n",
        "        'Endereço': extract_field(block, 'Endereço'),\n",
        "        'CEP': location_parts['CEP'] or extract_field(block, 'CEP'),\n",
        "        'Telefone': extract_field(block, 'Telefone'),\n",
        "        'E-mail': extract_email(block),\n",
        "        'Site': extract_field(block, 'Site')\n",
        "    }\n",
        "\n",
        "def parse_campus_block(block, uf_name):\n",
        "    \"\"\"Extrai e estrutura os dados de um bloco de Campus.\"\"\"\n",
        "    block_text = block.get_text('\\n', strip=True)\n",
        "\n",
        "    title_tag = block.find(['b', 'strong'])\n",
        "    campus_name_raw = title_tag.get_text(strip=True) if title_tag else \"\"\n",
        "\n",
        "    # Limpa e padroniza o nome do campus\n",
        "    campus_name_clean = re.sub(r'^(CAMPUS|AVANÇADO)\\s*', '', campus_name_raw, flags=re.IGNORECASE).strip()\n",
        "    campus_name = campus_name_clean.title() # Aplica Title Case\n",
        "\n",
        "    location_parts = parse_location_string(block_text, uf_name)\n",
        "\n",
        "    return {\n",
        "        'Campus_IF': campus_name,\n",
        "        'Município': location_parts['Município'],\n",
        "        'UF': location_parts['UF'],\n",
        "        'Endereço': extract_field(block, 'Endereço'),\n",
        "        'CEP': location_parts['CEP'] or extract_field(block, 'CEP'),\n",
        "        'Telefone': extract_field(block, 'Telefone'),\n",
        "        'E-mail': extract_email(block),\n",
        "    }\n",
        "\n",
        "\n",
        "def parse_address_string(address_str, uf_sigla):\n",
        "    \"\"\"\n",
        "    Analisa a string de endereço para extrair Endereço, Município, UF e CEP.\n",
        "\n",
        "    Args:\n",
        "        address_str (str): A string completa do endereço.\n",
        "        uf_sigla (str): A sigla da UF da página, usada como fallback.\n",
        "\n",
        "    Returns:\n",
        "        dict: Um dicionário contendo 'Endereço', 'Município', 'UF' e 'CEP'.\n",
        "    \"\"\"\n",
        "    if not address_str:\n",
        "        return {'Endereço': None, 'Município': None, 'UF': uf_sigla, 'CEP': None}\n",
        "\n",
        "    # Tenta extrair o CEP usando regex\n",
        "    cep_match = re.search(r'(\\d{5}-\\d{3})', address_str)\n",
        "    cep = cep_match.group(1) if cep_match else None\n",
        "\n",
        "    # Tenta extrair Município/UF\n",
        "    # Ex: \"Araraquara/SP\" ou \"São Lourenço do Oeste/SC\"\n",
        "    municipio_uf_match = re.search(r'([A-Za-z\\s\\'-]+)\\s*/\\s*([A-Z]{2})', address_str)\n",
        "    if municipio_uf_match:\n",
        "        municipio = municipio_uf_match.group(1).strip().rstrip('. ,')\n",
        "        uf = municipio_uf_match.group(2).strip()\n",
        "    else:\n",
        "        municipio = None\n",
        "        uf = uf_sigla # Usa a UF da página como fallback\n",
        "\n",
        "    return {'Endereço': address_str, 'Município': municipio, 'UF': uf, 'CEP': cep}\n",
        "\n",
        "def parse_reitoria_block(block, uf_sigla):\n",
        "    \"\"\"\n",
        "    Extrai e estrutura os dados de um bloco de Reitoria.\n",
        "    \"\"\"\n",
        "    block_text = block.get_text('\\n', strip=True) # Define block_text here\n",
        "    # Tenta encontrar a tag strong, se não encontrar, pega o texto do block e junta as linhas\n",
        "    nome_if_raw = block.find('strong').get_text(strip=True) if block.find('strong') else \" \".join(block.get_text(strip=True).split('\\n'))\n",
        "    nome_if = nome_if_raw.strip()\n",
        "\n",
        "    # Extrai a sigla do nome completo (ex: (IFSP))\n",
        "    sigla_match = re.search(r'\\((.*?)\\)', nome_if)\n",
        "    sigla_if = sigla_match.group(1) if sigla_match else None\n",
        "\n",
        "    address_str = extract_field(block, 'Endereço')\n",
        "    address_parts = parse_address_string(address_str, uf_sigla)\n",
        "\n",
        "    return {\n",
        "        'Sigla_IF': sigla_if,\n",
        "        'Nome_IF': nome_if,\n",
        "        'Campus_IF': 'Reitoria',\n",
        "        'Município': address_parts['Município'],\n",
        "        'UF': address_parts['UF'],\n",
        "        'Endereço': address_parts['Endereço'],\n",
        "        'CEP': address_parts['CEP'] or extract_field(block, 'CEP'),\n",
        "        'Telefone': extract_field(block, 'Telefone'),\n",
        "        'E-mail': extract_field(block, 'E-mail'),\n",
        "        'Site': extract_field(block, 'Site')\n",
        "    }"
      ],
      "metadata": {
        "id": "mgjBYcjKP8sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Montagem e Refinamento do DataFrame**\n",
        "O bloco final de código executa o processo de scraping, converte os resultados em um DataFrame pandas e realiza as últimas etapas de limpeza e formatação."
      ],
      "metadata": {
        "id": "z6-j6xDXTtmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXECUÇÃO PRINCIPAL ---\n",
        "\n",
        "# 1. Executa o motor de scraping para obter os dados brutos e o log\n",
        "scraped_data, run_log = scrape_all_ufs()\n",
        "\n",
        "# 2. Converte o log em um DataFrame para análise\n",
        "df_log = pd.DataFrame(run_log)\n",
        "\n",
        "# 3. Converte a lista de dicionários em um DataFrame\n",
        "if scraped_data:\n",
        "    df_mapa_RFEPT = pd.DataFrame(scraped_data)\n",
        "\n",
        "    # --- LIMPEZA E REFINAMENTO DO DATAFRAME ---\n",
        "\n",
        "    # Define a ordem desejada para as colunas\n",
        "    desired_columns = [\n",
        "        'Sigla_IF',\n",
        "        'Nome_IF',\n",
        "        'Campus_IF',\n",
        "        'Município',\n",
        "        'UF',\n",
        "        'Endereço',\n",
        "        'CEP',\n",
        "        'Telefone',\n",
        "        'E-mail',\n",
        "        'Site'\n",
        "    ]\n",
        "    # Reorganiza as colunas, mantendo apenas as que existem no DataFrame\n",
        "    # df_mapa_RFEPT = df_mapa_RFEPT.reindex(columns=[col for col in desired_columns if col in df_mapa_RFEPT.columns])\n",
        "    df_mapa_RFEPT = df_mapa_RFEPT.reindex(columns=desired_columns)\n",
        "\n",
        "    # Limpa possíveis caracteres indesejados nas colunas de texto\n",
        "    text_cols_to_clean = ['Sigla_IF', 'Nome_IF', 'Campus_IF', 'Município', 'UF', 'Endereço', 'CEP', 'Telefone', 'E-mail', 'Site']\n",
        "    for col in text_cols_to_clean:\n",
        "        if col in df_mapa_RFEPT.columns and df_mapa_RFEPT[col].dtype == 'object':\n",
        "            df_mapa_RFEPT[col] = df_mapa_RFEPT[col].astype(str).str.strip().replace('', pd.NA)\n",
        "\n",
        "    # Limpa espaços em branco extras\n",
        "    for col in text_cols_to_clean:\n",
        "        if col in df_mapa_RFEPT.columns:\n",
        "            df_mapa_RFEPT[col] = df_mapa_RFEPT[col].astype(str).str.strip()\n",
        "\n",
        "\n",
        "    # Normaliza números de telefone, removendo caracteres não numéricos\n",
        "    if 'Telefone' in df_mapa_RFEPT.columns:\n",
        "        # Garante que a coluna é string antes de aplicar regex\n",
        "        df_mapa_RFEPT['Telefone'] = df_mapa_RFEPT['Telefone'].astype(str).str.replace(r'[^\\d]', '', regex=True)\n",
        "        # Substitui strings vazias resultantes da limpeza por NA\n",
        "        df_mapa_RFEPT['Telefone'] = df_mapa_RFEPT['Telefone'].replace('', pd.NA)\n",
        "\n",
        "\n",
        "    # Exibe o log de execução\n",
        "    print(\"\\n--- Resumo da Execução do Scraping ---\")\n",
        "    print(df_log.to_string())\n",
        "\n",
        "    # Exibe informações e as primeiras linhas do DataFrame final\n",
        "    print(\"\\n--- Informações do DataFrame 'df_mapa_RFEPT' ---\")\n",
        "    df_mapa_RFEPT.info()\n",
        "\n",
        "    print(\"\\n--- Amostra dos Dados Coletados (df_mapa_RFEPT) ---\")\n",
        "    display(df_mapa_RFEPT.head(10))\n",
        "\n",
        "else:\n",
        "    print(\"\\nNenhum dado foi extraído. O DataFrame 'df_mapa_RFEPT' não pôde ser criado.\")\n",
        "    print(\"\\n--- Resumo da Execução do Scraping ---\")\n",
        "    print(df_log.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8NapYGy-Qgty",
        "outputId": "a957f8f7-ba67-4a16-a94b-c9b588272065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando processo de extração de dados da Rede Federal...\n",
            "Processando UF: ACRE | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/acre\n",
            "  -> Sucesso: 7 unidades encontradas.\n",
            "Processando UF: ALAGOAS | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/alagoas\n",
            "  -> Sucesso: 17 unidades encontradas.\n",
            "Processando UF: AMAPA | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/amapa\n",
            "  -> Sucesso: 7 unidades encontradas.\n",
            "Processando UF: AMAZONAS | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/amazonas\n",
            "  -> Sucesso: 18 unidades encontradas.\n",
            "Processando UF: BAHIA | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/bahia\n",
            "  -> Sucesso: 41 unidades encontradas.\n",
            "Processando UF: CEARA | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/ceara\n",
            "  -> Sucesso: 34 unidades encontradas.\n",
            "Processando UF: DISTRITO-FEDERAL | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/distrito-federal\n",
            "  -> Sucesso: 11 unidades encontradas.\n",
            "Processando UF: ESPIRITO-SANTO | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/espirito-santo\n",
            "  -> Sucesso: 22 unidades encontradas.\n",
            "Processando UF: GOIAS | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/goias\n",
            "  -> Sucesso: 28 unidades encontradas.\n",
            "Processando UF: MARANHAO | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/maranhao\n",
            "  -> Sucesso: 32 unidades encontradas.\n",
            "Processando UF: MATO-GROSSO | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/mato-grosso\n",
            "  -> Sucesso: 20 unidades encontradas.\n",
            "Processando UF: MATO-GROSSO-DO-SUL | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/mato-grosso-do-sul\n",
            "  -> Sucesso: 11 unidades encontradas.\n",
            "Processando UF: MINAS-GERAIS | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/minas-gerais\n",
            "  -> Sucesso: 62 unidades encontradas.\n",
            "Processando UF: PARA | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/para\n",
            "  -> Sucesso: 19 unidades encontradas.\n",
            "Processando UF: PARAIBA | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/paraiba\n",
            "  -> Sucesso: 23 unidades encontradas.\n",
            "Processando UF: PARANA | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/parana\n",
            "  -> Sucesso: 43 unidades encontradas.\n",
            "Processando UF: PERNAMBUCO | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/pernambuco\n",
            "  -> Sucesso: 24 unidades encontradas.\n",
            "Processando UF: PIAUI | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/piaui\n",
            "  -> Sucesso: 22 unidades encontradas.\n",
            "Processando UF: RIO-DE-JANEIRO | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/rio-de-janeiro\n",
            "  -> Sucesso: 28 unidades encontradas.\n",
            "Processando UF: RIO-GRANDE-DO-NORTE | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/rio-grande-do-norte\n",
            "  -> Sucesso: 22 unidades encontradas.\n",
            "Processando UF: RIO-GRANDE-DO-SUL | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/rio-grande-do-sul\n",
            "  -> Sucesso: 29 unidades encontradas.\n",
            "Processando UF: RONDONIA | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/rondonia\n",
            "  -> Sucesso: 12 unidades encontradas.\n",
            "Processando UF: RORAIMA | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/roraima\n",
            "  -> Sucesso: 7 unidades encontradas.\n",
            "Processando UF: SANTA-CATARINA | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/santa-catarina\n",
            "  -> Sucesso: 39 unidades encontradas.\n",
            "Processando UF: SAO-PAULO | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/sao-paulo\n",
            "  -> Sucesso: 42 unidades encontradas.\n",
            "Processando UF: SERGIPE | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/sergipe\n",
            "  -> Sucesso: 11 unidades encontradas.\n",
            "Processando UF: TOCANTINS | URL: https://www.gov.br/mec/pt-br/assuntos/ept/rede-federal/tocantins\n",
            "  -> Sucesso: 12 unidades encontradas.\n",
            "\n",
            "Processo de extração finalizado.\n",
            "\n",
            "--- Resumo da Execução do Scraping ---\n",
            "                     UF   Status  Units Found\n",
            "0                  ACRE  Success            7\n",
            "1               ALAGOAS  Success           17\n",
            "2                 AMAPA  Success            7\n",
            "3              AMAZONAS  Success           18\n",
            "4                 BAHIA  Success           41\n",
            "5                 CEARA  Success           34\n",
            "6      DISTRITO-FEDERAL  Success           11\n",
            "7        ESPIRITO-SANTO  Success           22\n",
            "8                 GOIAS  Success           28\n",
            "9              MARANHAO  Success           32\n",
            "10          MATO-GROSSO  Success           20\n",
            "11   MATO-GROSSO-DO-SUL  Success           11\n",
            "12         MINAS-GERAIS  Success           62\n",
            "13                 PARA  Success           19\n",
            "14              PARAIBA  Success           23\n",
            "15               PARANA  Success           43\n",
            "16           PERNAMBUCO  Success           24\n",
            "17                PIAUI  Success           22\n",
            "18       RIO-DE-JANEIRO  Success           28\n",
            "19  RIO-GRANDE-DO-NORTE  Success           22\n",
            "20    RIO-GRANDE-DO-SUL  Success           29\n",
            "21             RONDONIA  Success           12\n",
            "22              RORAIMA  Success            7\n",
            "23       SANTA-CATARINA  Success           39\n",
            "24            SAO-PAULO  Success           42\n",
            "25              SERGIPE  Success           11\n",
            "26            TOCANTINS  Success           12\n",
            "\n",
            "--- Informações do DataFrame 'df_mapa_RFEPT' ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 643 entries, 0 to 642\n",
            "Data columns (total 10 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Sigla_IF   643 non-null    object\n",
            " 1   Nome_IF    643 non-null    object\n",
            " 2   Campus_IF  643 non-null    object\n",
            " 3   Município  643 non-null    object\n",
            " 4   UF         643 non-null    object\n",
            " 5   Endereço   643 non-null    object\n",
            " 6   CEP        643 non-null    object\n",
            " 7   Telefone   305 non-null    object\n",
            " 8   E-mail     643 non-null    object\n",
            " 9   Site       643 non-null    object\n",
            "dtypes: object(10)\n",
            "memory usage: 50.4+ KB\n",
            "\n",
            "--- Amostra dos Dados Coletados (df_mapa_RFEPT) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Sigla_IF                                            Nome_IF  \\\n",
              "0     None  INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...   \n",
              "1     None  INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...   \n",
              "2     None  INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...   \n",
              "3     None  INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...   \n",
              "4     None  INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...   \n",
              "5     None  INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...   \n",
              "6     None  INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...   \n",
              "7     None  INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...   \n",
              "8     None  INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...   \n",
              "9     None  INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...   \n",
              "\n",
              "                         Campus_IF Município       UF  \\\n",
              "0                         Reitoria      None     ACRE   \n",
              "1                  Cruzeiro Do Sul      None     ACRE   \n",
              "2                       Rio Branco      None     ACRE   \n",
              "3        Rio Branco Baixada Do Sol      None     ACRE   \n",
              "4                   Sena Madureira      None     ACRE   \n",
              "5                         Tarauacá      None     ACRE   \n",
              "6                           Xapuri      None     ACRE   \n",
              "7                         Reitoria      None  ALAGOAS   \n",
              "8                        Arapiraca      None  ALAGOAS   \n",
              "9  Avançado Maceió Benedito Bentes      None  ALAGOAS   \n",
              "\n",
              "                                            Endereço        CEP    Telefone  \\\n",
              "0                                               None       None        <NA>   \n",
              "1     Rua Paraná, 25 de agosto. Cruzeiro do Sul, AC.   6998000.  4999820966   \n",
              "2  Av. Brasil, Xavier Maia. Rio Branco, AC. CEP: ...  69914-610  6821065910   \n",
              "3  Rua Rio Grande do Sul, Aeroporto Velho. Rio Br...  69911-030  6832246816   \n",
              "4  TRAVESSA GUILHERME, Pista. Sena Madureira, AC....  69940-970  6836122797   \n",
              "5  Rua Coronel Juvêncio de Menezes, Rua João Pess...  69970-000  6834621709   \n",
              "6  Rua Seis de Agosto, Centro. Xapuri, AC. CEP: 6...  69930-000        <NA>   \n",
              "7                                               None       None        <NA>   \n",
              "8  Rodovia AL-110, Próximo Rotatória Polícia Rodo...  57302-045  8231941150   \n",
              "9  Avenida Benedito Bentes, Benedito Bentes. Mace...  57084-651  8221266230   \n",
              "\n",
              "                 E-mail  Site  \n",
              "0                  None  None  \n",
              "1                  None  None  \n",
              "2                  None  None  \n",
              "3  reitoria@ifac.edu.br  None  \n",
              "4                  None  None  \n",
              "5                  None  None  \n",
              "6                  None  None  \n",
              "7                  None  None  \n",
              "8                  None  None  \n",
              "9                  None  None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8267d37-2f08-4ccb-bf4d-83294744f5fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sigla_IF</th>\n",
              "      <th>Nome_IF</th>\n",
              "      <th>Campus_IF</th>\n",
              "      <th>Município</th>\n",
              "      <th>UF</th>\n",
              "      <th>Endereço</th>\n",
              "      <th>CEP</th>\n",
              "      <th>Telefone</th>\n",
              "      <th>E-mail</th>\n",
              "      <th>Site</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "      <td>INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...</td>\n",
              "      <td>Reitoria</td>\n",
              "      <td>None</td>\n",
              "      <td>ACRE</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "      <td>INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...</td>\n",
              "      <td>Cruzeiro Do Sul</td>\n",
              "      <td>None</td>\n",
              "      <td>ACRE</td>\n",
              "      <td>Rua Paraná, 25 de agosto. Cruzeiro do Sul, AC.</td>\n",
              "      <td>6998000.</td>\n",
              "      <td>4999820966</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "      <td>INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...</td>\n",
              "      <td>Rio Branco</td>\n",
              "      <td>None</td>\n",
              "      <td>ACRE</td>\n",
              "      <td>Av. Brasil, Xavier Maia. Rio Branco, AC. CEP: ...</td>\n",
              "      <td>69914-610</td>\n",
              "      <td>6821065910</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "      <td>INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...</td>\n",
              "      <td>Rio Branco Baixada Do Sol</td>\n",
              "      <td>None</td>\n",
              "      <td>ACRE</td>\n",
              "      <td>Rua Rio Grande do Sul, Aeroporto Velho. Rio Br...</td>\n",
              "      <td>69911-030</td>\n",
              "      <td>6832246816</td>\n",
              "      <td>reitoria@ifac.edu.br</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "      <td>INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...</td>\n",
              "      <td>Sena Madureira</td>\n",
              "      <td>None</td>\n",
              "      <td>ACRE</td>\n",
              "      <td>TRAVESSA GUILHERME, Pista. Sena Madureira, AC....</td>\n",
              "      <td>69940-970</td>\n",
              "      <td>6836122797</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>None</td>\n",
              "      <td>INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...</td>\n",
              "      <td>Tarauacá</td>\n",
              "      <td>None</td>\n",
              "      <td>ACRE</td>\n",
              "      <td>Rua Coronel Juvêncio de Menezes, Rua João Pess...</td>\n",
              "      <td>69970-000</td>\n",
              "      <td>6834621709</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>None</td>\n",
              "      <td>INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...</td>\n",
              "      <td>Xapuri</td>\n",
              "      <td>None</td>\n",
              "      <td>ACRE</td>\n",
              "      <td>Rua Seis de Agosto, Centro. Xapuri, AC. CEP: 6...</td>\n",
              "      <td>69930-000</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>None</td>\n",
              "      <td>INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...</td>\n",
              "      <td>Reitoria</td>\n",
              "      <td>None</td>\n",
              "      <td>ALAGOAS</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>None</td>\n",
              "      <td>INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...</td>\n",
              "      <td>Arapiraca</td>\n",
              "      <td>None</td>\n",
              "      <td>ALAGOAS</td>\n",
              "      <td>Rodovia AL-110, Próximo Rotatória Polícia Rodo...</td>\n",
              "      <td>57302-045</td>\n",
              "      <td>8231941150</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>None</td>\n",
              "      <td>INSTITUTO FEDERAL DE EDUCAÇÃO, CIÊNCIA E TECNO...</td>\n",
              "      <td>Avançado Maceió Benedito Bentes</td>\n",
              "      <td>None</td>\n",
              "      <td>ALAGOAS</td>\n",
              "      <td>Avenida Benedito Bentes, Benedito Bentes. Mace...</td>\n",
              "      <td>57084-651</td>\n",
              "      <td>8221266230</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8267d37-2f08-4ccb-bf4d-83294744f5fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f8267d37-2f08-4ccb-bf4d-83294744f5fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f8267d37-2f08-4ccb-bf4d-83294744f5fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4ef23210-c2d0-4d8f-b6bd-d602953180c5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ef23210-c2d0-4d8f-b6bd-d602953180c5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4ef23210-c2d0-4d8f-b6bd-d602953180c5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(df_log\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Sigla_IF\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"None\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nome_IF\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"INSTITUTO FEDERAL DE EDUCA\\u00c7\\u00c3O, CI\\u00caNCIA E TECNOLOGIA DE ALAGOAS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Campus_IF\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Arapiraca\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Munic\\u00edpio\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"None\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UF\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ALAGOAS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Endere\\u00e7o\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Rodovia AL-110, Pr\\u00f3ximo Rotat\\u00f3ria Pol\\u00edcia Rodovi\\u00e1ria Estadual - Acesso Taquarana, Senador Arnon de Melo.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CEP\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"57302-045\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Telefone\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"4999820966\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"E-mail\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"reitoria@ifac.edu.br\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Site\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"None\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **ETAPA 2.2. Exportar DataFrame `df_mapa_RFEPT`para Google Sheets por ID**\n",
        "\n",
        "# ======================== Configurações da Planilha ========================\n",
        "# ID da planilha\n",
        "ID_PLANILHA = '19JkJDxBOuuoED-IMt07ofEKWy5fxnIOf5BbZikM2HPM'\n",
        "# Nome da aba, se não existir, será criada.\n",
        "NOME_ABA = 'Web_Scraping_Mapa_RFEPCT'\n",
        "# ==============================================================\n",
        "\n",
        "# 1. Autenticação do Google Colab\n",
        "print(\"Autenticando-se no Google...\")\n",
        "# Inicia autenticação no Google\n",
        "auth.authenticate_user()\n",
        "print(\"Autenticação concluída.\")\n",
        "\n",
        "# 2. Inicializar o cliente gspread\n",
        "# Utilizar as credenciais padrão estabelecidas pelo auth.authenticate_user()\n",
        "credentials, project = google.auth.default()\n",
        "gc = Client(auth=credentials)\n",
        "\n",
        "try:\n",
        "    # 3. Abrir a planilha usando o ID (Chave)\n",
        "    sh = gc.open_by_key(ID_PLANILHA)\n",
        "    print(f\"Planilha ID: '{ID_PLANILHA}' acessada com sucesso.\")\n",
        "\n",
        "    # 4. Selecionar ou criar a aba (worksheet)\n",
        "    try:\n",
        "        # Tenta selecionar a aba existente\n",
        "        worksheet = sh.worksheet(NOME_ABA)\n",
        "        # Limpa o conteúdo existente para substituí-lo\n",
        "        worksheet.clear()\n",
        "        print(f\"Aba '{NOME_ABA}' limpa e pronta para receber os novos dados.\")\n",
        "    except gspread.exceptions.WorksheetNotFound:\n",
        "        # Se não encontrar, adiciona uma nova aba\n",
        "        # Adicionamos um número grande de linhas/colunas para garantir espaço\n",
        "        worksheet = sh.add_worksheet(title=NOME_ABA, rows=\"1000\", cols=\"15\")\n",
        "        print(f\"Aba '{NOME_ABA}' criada.\")\n",
        "\n",
        "\n",
        "    # 5. Converter o DataFrame para uma lista de listas (formato que o gspread usa)\n",
        "    # Inclui o cabeçalho (nomes das colunas)\n",
        "    # Usar .tolist() (sem underscore) para converter o array NumPy\n",
        "    # Certifica-se que df_rede_federal está definido e não vazio\n",
        "    if 'df_mapa_RFEPT' in locals() and not df_mapa_RFEPT.empty:\n",
        "        # Replace pd.NA with None for JSON serialization\n",
        "        df_mapa_RFEPT_cleaned = df_mapa_RFEPT.replace({pd.NA: None})\n",
        "        dados_para_sheet = [df_mapa_RFEPT_cleaned.columns.tolist()] + df_mapa_RFEPT_cleaned.values.tolist()\n",
        "    else:\n",
        "        raise ValueError(\"DataFrame 'df_mapa_RFEPT' não encontrado ou está vazio.\")\n",
        "\n",
        "\n",
        "    # 6. Exportar os dados (atualiza toda a faixa a partir de A1)\n",
        "    # Usar argumentos nomeados para evitar o DeprecationWarning\n",
        "    worksheet.update(values=dados_para_sheet, range_name='A1')\n",
        "\n",
        "    # 7. Exibir o link\n",
        "    print(\"-\" * 50)\n",
        "    print(\"Exportação concluída com sucesso!\")\n",
        "    print(f\"Acesse a planilha aqui: {sh.url}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "except gspread.exceptions.SpreadsheetNotFound:\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"ERRO: Planilha com ID '{ID_PLANILHA}' não encontrada.\")\n",
        "    print(\"Verifique se o ID está correto ou se você possui acesso a ela.\")\n",
        "    print(\"-\" * 50)\n",
        "except gspread.exceptions.APIError as e:\n",
        "    print(\"-\" * 50)\n",
        "    print(\"ERRO DE API (Permissão):\")\n",
        "    print(\"Verifique se a conta Google usada na autenticação tem permissão de 'Editor' na planilha.\")\n",
        "    print(f\"Detalhes do erro: {e}\")\n",
        "    print(\"-\" * 50)\n",
        "except Exception as e:\n",
        "    # Captura outros erros, incluindo problemas de permissão\n",
        "    print(f\"Ocorreu um erro inesperado durante a exportação: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263da808-bec7-4495-acd0-af17eb027cab",
        "id": "a6C76qP8jslD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autenticando-se no Google...\n",
            "Autenticação concluída.\n",
            "Planilha ID: '19JkJDxBOuuoED-IMt07ofEKWy5fxnIOf5BbZikM2HPM' acessada com sucesso.\n",
            "Aba 'Web_Scraping_Mapa_RFEPCT' limpa e pronta para receber os novos dados.\n",
            "--------------------------------------------------\n",
            "Exportação concluída com sucesso!\n",
            "Acesse a planilha aqui: https://docs.google.com/spreadsheets/d/19JkJDxBOuuoED-IMt07ofEKWy5fxnIOf5BbZikM2HPM\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}